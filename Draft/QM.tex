\documentclass[cyan]{elegantnote}
\author{Yuyang Songsheng}
\email{songshengyuyang@gmail.com}
\zhtitle{物理}
\entitle{Physics}
\version{1.00}
\myquote{Do not ask what it is. Ask what you can say about it.}
\logo{logo.jpg}
\cover{cover.pdf}
%green color
   \definecolor{main1}{RGB}{210,168,75}
   \definecolor{seco1}{RGB}{9,80,3}
   \definecolor{thid1}{RGB}{0,175,152}
%cyan color
   \definecolor{main2}{RGB}{239,126,30}
   \definecolor{seco2}{RGB}{0,175,152}
   \definecolor{thid2}{RGB}{236,74,53}
%cyan color
   \definecolor{main3}{RGB}{127,191,51}
   \definecolor{seco3}{RGB}{0,145,215}
   \definecolor{thid3}{RGB}{180,27,131}


\usepackage{makecell}
\usepackage{lipsum}
\usepackage{amssymb}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{latexsym}
\usepackage{hyperref}
\usepackage{feynmf}
\usepackage{exscale}
\usepackage{relsize}
\usepackage{bm}%bold math, for vector


\begin{document}
\maketitle
\tableofcontents
\chapter{Linear Algebra}
\section{Linear Vector Space}
\subsection{Definition}
\begin{newdef}[Linear vector space]
A linear vector space is a set of elements, called vectors, which is closed under addition and multiplication by scalars. That is to say, if $\phi$ and $\psi$ are vectors then so is $a\phi+b\psi$, where $a$ and $b$ are arbitrary scalars. If the scalars belong to the field of complex (real) numbers, we speak of a complex (real) linear vector space. Henceforth the scalars will be complex numbers unless otherwise stated.
\end{newdef}

\begin{example}
\begin{enumerate}
\item Discrete vectors, which may be represented as columns of complex numbers.
\item Spaces of functions of some type, for example the space of all differentiable functions
\end{enumerate}
\end{example}

\subsection{Linear independence}
\begin{newdef}[Linear independence]
A set of vectors $\{\phi_n\}$ is said to be linearly independent if no non-trivial linear combination of them sums to zero; that is to say, if the equation $\sum_{n} c_n \phi_n$ can hold only when $c_n=0$ for all $n$. If this condition does not hold, the set of vectors is said to be linearly dependent, in which case it is possible to express a member of the set as a linear combination of the others.
\end{newdef}

\begin{newdef}[Dimension]
The maximum number of linearly independent vectors in a space is called the dimension of the space.
\end{newdef}

\begin{newdef}[Base]
A maximal set of linearly independent vectors is called a basis for the space. Any vector in the space can be expressed as a linear combination of the basis vectors.
\end{newdef}

\subsection{Inner product}
\begin{newdef}[Inner product]
An inner product (or scalar product) for a linear vector space associates a scalar $(\phi,\psi)$ with every ordered pair of vectors. 
It must satisfy the following properties:
\begin{enumerate}
\item $(\phi,\psi) = $ a complex number
\item $(\phi,\psi) = (\psi,\phi)^*$
\item $(\phi,c_1\psi_1 + c_2\psi_2) = c_1(\phi,\psi_1) + c_2(\phi,\psi_2)$
\item $(\phi,\phi) geq 0$,with equality holding if and only if $\phi=0$
\end{enumerate}
\end{newdef}

\begin{example}
\begin{enumerate}
\item If $\psi$ is the column vector with elements $a_1$, $a_2$, $\cdots$, and $\phi$ is the column vector with elements $b_1$, $b_2$, $\cdots$, then
\[(\psi,\phi) = a_1^*b_1 + a_2^*b_2 + \cdots\]
\item If $\psi$ and $\phi$ are functions of $x$, then
\[(\phi,\psi) = \int \phi^*(x) \psi(x) w(x) dx\]
where $w(x)$ is some non-negative weight function.
\end{enumerate}
\end{example}

\begin{newdef}[Norm]
\[|| \phi || = (\phi,\phi)^{\frac{1}{2}}\]
\end{newdef}

\begin{newthem}[Schwarz's inequality]
\[|(\psi,\phi)|^2 \leq (\psi,\psi)(\phi,\phi)\]
\end{newthem}

\begin{newthem}[triangle inequality]
\[||(\psi+\phi)|| \leq ||\phi|| + ||\psi||\]
\end{newthem}

\begin{newdef}[Orthonormal]
A set of vectors $\{\phi_n\}$ is said to be orthonormal if the vectors are pairwise orthogonal and of unit norm; that is to say, their inner products satisfy $(\psi_m,\phi_n) = \delta_{mn}$.
\end{newdef}

\subsection{Dual space}
\begin{newdef}[Dual vector]
Corresponding to any linear vector space $V$ there exists the dual space of linear functionals on $V$ . A linear functional $F$ assigns a scalar $F(\phi)$ to each vector $\phi$, such that
\[F(a\phi+b\psi) = aF(\phi) + bF(\psi)\]
for any vectors for $\phi$ and $\psi$, and any scalars $a$ and $b$. The set of linear functionals may itself be regarded as forming a linear space $V'$ if we define the sum of two functionals as
\[(F_1+F_2)(\phi) = F_1(\phi) + F_2(\phi)\]
\end{newdef}

\begin{newthem}[Riesz theorem] 
There is a one-to-one correspondence between linear functionals $F$ in $V'$ and vectors $f$ in $V$, such that all linear functionals have the form
\[F(\phi) = (f,\phi)\]
$f$ being a fixed vector, and $\phi$ being an arbitrary vector. Thus the spaces $V$ and $V'$ are essentially isomorphic.
\end{newthem}

\subsection{Dirac's bra and ket notation}
\noindent
In Dirac’s notation, which is very popular in quantum mechanics, the vectors in $V$ are called ket vectors, and are denoted as $|\phi \rangle$. The linear functionals in the dual space $V'$ are called bra vectors, and are denoted as $\langle F |$. The numerical value of the functional is denoted as
\[F(\phi) = \langle F | \phi \rangle\]
According to the Riesz theorem, there is a one-to-one correspondence between bras and kets. Therefore we can use the same alphabetic character for the functional (a member of $V'$) and the vector (in $V$ ) to which it corresponds, relying on the bra, $\langle F |$, or ket, $|F\rangle$, notation to determine which space is referred to.So
\[\langle F | \phi \rangle = (F,\phi)\]
Note that the Riesz theorem establishes, by construction, an antilinear correspondence between bras and kets. If $\langle F | \leftrightarrow  |F\rangle$, then
\[c_1^* \langle F_1 | + c_2^* \langle F_2 | \leftrightarrow  c_1 |F_1\rangle + c_2|F_2\rangle\]

\section{Linear Operators}
\begin{newdef}[Linear operators]
An operator on a vector space maps vectors onto vectors.
A linear operator satisfies
\[A (c_1 \psi_1 + c_2 \psi_2) = c_1 A(\psi_1) + c_2 A(\psi_2)\]
Define the sum and product of operators,
\begin{eqnarray}
(A+B)\psi &=& A\psi + B\psi \nonumber \\
A B \psi &=& A (B\psi) \nonumber
\end{eqnarray}
Define their action to the left on bra vectors as
\[(\langle \phi | A ) \psi \rangle = \langle \phi | ( A | \psi \rangle )\]
So we may define the operation of $A$ on the bra space of functionals as
\[A F_{\phi} (\psi) = F_{\phi}(A\psi)\]
According to the Riesz theorem there must exist a ket vector $\chi$ such that
\[AF_{\phi}(\psi) = (\chi, \psi) = F_{\chi}(\psi)\]
Define operator $A^{\dagger}$ as
\[AF_{\phi} = F_{A^{\dagger}\chi}\]
Therefore,
\[(A^{\dagger}\phi, \psi) = (\phi, A\psi)\]
\[\langle \psi | A^{\dagger} | \phi \rangle ^* = \langle \phi | A | \psi \rangle\]
\end{newdef}

\begin{newdef}[Outer product]
\[(| \psi \rangle \langle \phi |) | \lambda \rangle \equiv | \psi \rangle (\langle \phi | \lambda \rangle)\]
\end{newdef}

\begin{newdef}[Trace]
\[ \mathrm{Tr} A \equiv \sum \langle u_j | A | u_j \rangle \]
where $\{ u_j \}$ may be any orthonormal basis. It can be shown that the value of $\mathrm{Tr}A$ is independent of the particular orthonormal basis that is chosen for its evaluation.
\end{newdef}

\begin{newprop}
\begin{eqnarray}
(cA)^{\dagger} &=& c^* A^{\dagger} \nonumber \\
(A + B)^{\dagger} &=& A^{\dagger} + B^{\dagger} \nonumber \\
(AB)^{\dagger} &=& B^{\dagger}  A^{\dagger} \nonumber
\end{eqnarray}
\[(| \psi \rangle \langle \phi |) ^ {\dagger} = | \phi \rangle \langle \psi |\]
\end{newprop}

\section{Self-Adjoint operators}
\begin{newdef}[Self-Adjoint operators]
An operator $A$ that is equal to its adjoint $A^{\dagger}$ is called self-adjoint. This means that it satisfies
\[\langle \phi | A | \psi \rangle  = \langle \psi | A | \phi \rangle^*\]
and that the domain of $A$ coincides with the domain of $A^{\dagger}$. An operator that only satisfies above equation is called Hermitian.
\end{newdef}

\begin{newthem}
If $\langle \psi | A | \psi \rangle  = \langle \psi | A | \psi \rangle^*$ for all $| \psi \rangle$, then it follows that $\langle \phi_1 | A | \phi_2 \rangle  = \langle \phi_2 | A | \phi_1 \rangle^*$ for all $|\phi_1\rangle$ and $|\phi_2\rangle$, and hence that $A = A^{\dagger}$.\\
If an operator acting on a certain vector produces a scalar multiple of that same vector,
\[ A |\phi \rangle = a |\phi \rangle\]
we call the vector $| \phi \rangle$ an eigenvector and the scalar a an eigenvalue of the operator $A$. The antilinear correspondence between bras and kets, and the definition of the adjoint operator $A^{\dagger}$, imply that the left-handed eigenvalue equation
\[\langle \phi | A^{\dagger} = a^{*} \langle \phi |\]
\end{newthem}

\begin{newthem}
 If $A$ is a Hermitian operator then all of its eigenvalues are real.
\end{newthem}

\begin{newthem}
Eigenvectors corresponding to distinct eigenvalues of a Hermitian operator must be orthogonal.
\end{newthem}

\noindent
If the orthonormal set of vectors $\{ \phi_i \}$ is complete, then we can expand an arbitrary vector $|v\rangle$ in terms of it:
\[ |v\rangle = \sum | \phi_i \rangle (\langle \phi_i | v \rangle) = \left( \sum |\phi_i \rangle \langle \phi_i | \right) | v\rangle\]
So,
\[ \sum |\phi_i \rangle \langle \phi_i | = I\]
If $A |\phi_i \rangle = a_i |\phi_i\rangle$ and the eigenvectors form a complete orthonormal set, then the operator can be reconstructed in a useful diagonal form in terms of its eigenvalues and eigenvectors:
\[A = \sum a_i |\phi_i \rangle \langle \phi_i |\]
We can define a function of an operator
\[f(A) =  \sum f(a_i) |\phi_i \rangle \langle \phi_i |\]
The Hermitian operators in a finite N-dimensional vector space have complete sets of eigenvectors. But This statement does not carry over to infinite-dimensional spaces. A Hermitian operator in an infinite dimensional vector space may or may not possess a complete set of eigenvectors, depending upon the precise nature of the operator and the vector space. Instead, we have spectral theorem.

\begin{newthem}
To each self-adjoint operator $A$ there corresponds a unique family of projection operators, $E(\lambda)$, for real $\lambda$, with the properties:
\begin{enumerate}
\item If $\lambda_1 < \lambda_2$ then $E(\lambda_1)E(\lambda_2) = E(\lambda_2)E(\lambda_1)= E(\lambda_1) $
\item If $\epsilon > 0$, then $E(\lambda + \epsilon)|\psi\rangle \to E(\lambda)|\psi\rangle$ as $\epsilon \to 0$
\item $E(\lambda)|\psi\rangle \to 0$ as $\lambda \to -\infty$
\item $E(\lambda)|\psi\rangle \to |\psi\rangle$ as $\lambda \to \infty$
\item $\int_{-\infty}^{\infty} \lambda dE(\lambda) = A$
\end{enumerate}
\end{newthem}

\noindent
We can define a function of an operator
\[f(A) = \int_{-\infty}^{\infty} f(\lambda) dE(\lambda)\]
Following Dirac’s pioneering formulation, it has become customary in
quantum mechanics to write a formal eigenvalue equation for an operator such as $Q$ that has a continuous spectrum,
\[Q |q\rangle = q|q\rangle\]
The orthonormality condition for the continuous case takes the form
\[\langle q' | q'' \rangle = \delta(q-q')\]
Evidently the norm of these formal eigenvectors is infinite, since 
$\langle q | q \rangle \to \infty$. Instead of the spectral theorem for $Q$, Dirac would write
\[Q = \int_{-\infty}^{\infty} q |q\rangle\langle q| dq\]
Dirac’s formulation does not fit into the mathematical theory of Hilbert space, which admits only vectors of finite norm. The projection operator formally given by
\[E(\lambda) = \int_{-\infty}^{\lambda}  |q\rangle\langle q| dq\]
is is well defined in Hilbert space, but its derivative does not
exist within the Hilbert space framework.

\begin{newthem}
 If $A$ and $B$ are self-adjoint operators, each of which possesses a complete set of eigenvectors, and if $AB =BA$, then there exists a complete set of vectors which are eigenvectors of both $A$ and $B$.
\end{newthem}

Let $(A, B, \cdots)$ be a set of mutually commutative operators that possess a complete set of common eigenvectors. Corresponding to a particular eigenvalue for each operator, there may be more than one eigenvector. If, however, there is no more than one eigenvector (apart from the arbitrary phase and normalization) for each set of eigenvalues $(a_n, b_m, \cdots)$, then the operators $(A, B, \cdots)$ are said to be a complete commuting set of operators.

\begin{newthem}
Any operator that commutes with all members of a complete commuting set must be a function of the operators in that set.
\end{newthem}

\section{Rigged Hilbert space}
\begin{newdef}[Rigged Hilbert spece]
Formally, a rigged Hilbert space consists of a Hilbert space $\mathcal{H}$, together with a subspace $\Phi$ which carries a finer topology, that is one for which the natural inclusion $\Phi \subseteq \mathcal{H}$ is continuous. 
It is no loss to assume that $\Phi$ is dense in $\mathcal{H}$ for the Hilbert norm. We consider the inclusion of conjugate space $\mathcal{H}^X$ in $\Phi^X$. $\Phi^X$ is the space of $\tau_{\Phi}$ continuous antilinear functional on $\Phi$.\\
For any $\phi \in \Phi$, $F \in \Phi^X$,we define
\[\langle \phi | F \rangle \equiv F(\phi)\]
\[\langle F | \phi \rangle \equiv [F(\phi)]^*\]
Now by applying the Riesz representation theorem we can identify $\mathcal{H}^X$ with $\mathcal{H}$. Therefore, the definition of rigged Hilbert space is in terms of a sandwich:
\[\Phi \subseteq \mathcal{H} \subseteq \Phi^X\]
\end{newdef}
There may or may not exist any solutions to the eigenvalue equation $A|a_n\rangle = a_n |a_n\rangle$ for a self-adjoint operator $A$ on an infinite-dimensional vector space. However, the generalized spectral theorem asserts that if $A$ is self-adjoint in $\mathcal{H}$ then a complete set of eigenvectors exists in the extended space $\Phi^X$. The precise conditions for the proof of this theorem are rather technical, so the interested reader is referred to \emph{Gel'fand and Vilenkin (1964)} for further details.

There are many examples of rigged-Hilbert-space triplets. A Hilbert space $\mathcal{H}$ is formed by those functions that are square-integrable. That is, $\mathcal{H}$ consists of those functions $\psi(x)$ for which
\[\langle \psi | \psi \rangle = \int_{-\infty}^{\infty} |\psi(x)|^2 dx \mbox{ is finite }\]
A nuclear space $\Phi$ is made up of functions $\psi(x)$ which satisfy the infinite set of conditions,
\[\ \int_{-\infty}^{\infty} |\psi(x)|^2(1+|x|)^m dx \mbox{ is finite for } m = 0,1,2,\cdots\]
The functions $\psi(x)$) which make up $\Phi$ must vanish more rapidly than any inverse power of $x$ in the limit $|x| \to \infty$. The extended space $\Phi^X$, which is conjugate to $\Phi$, consists of those functions $\chi(x)$ for which
\[\langle \chi | \psi \rangle = \int_{-\infty}^{\infty} \chi^*(x)\psi(x) dx \mbox{ is finite for any } \psi \mbox{ in } \Phi\]

In addition to the functions of finite norm, which also lie in $\mathcal{H}$, $\Phi^X$ will contain functions that are unbounded at infinity provided the divergence is no worse than a power of $x$. Hence $\Phi^X$ contains $e^{ikx}$, which is an eigenfunction
of the operator $D = i \frac{d}{dx}$. It also contains the Dirac delta function, $\delta(x-\lambda)$, which is an eigenfunction of the operator $X$, defined by $X\psi(x) = x\psi(x)$.
These two examples suffice to show that rigged Hilbert space seems to be a more natural mathematical setting for quantum mechanics than is Hilbert space.

\section{Unitary operators}
\begin{newdef}[Unitary operator]
 A unitary operator is a bounded linear operator $U: H\to H$ on a Hilbert space $H$ that satisfies $UU^{\dagger} = U^{\dagger}U =I$, where $U^{\dagger}$ is the adjoint of $U$, and $I: H \to H$ is the identity operator.
\end{newdef}
\noindent
Consider a family of unitary operators, $U(s)$, that depend on a single continuous parameter $s$. 
Let $U(0) = I $ be the identity operator, and let $U(s_1+s_2) = U(s_1)U(s_2)$.
We can demonstrate that
\[\left. \frac{dU}{ds}\right|_{s=0} = iK \mbox{ with } K = K^{\dagger}\]
The Hermitian operator $K$ is called the generator of the family of unitary operators because it determines $U(s)$, not only for infinitesimal $s$, but for all $s$. This can be shown by differentiating
\[U(s_1+s_2) = U(s_1)U(s_2)\]
with respect to $s_2$ and we can get
\[\left. \frac{dU}{ds}\right|_{s=s_1} = U(s_1)iK \]
This first order differential equation with initial condition $U(0) = I$ has the unique solution
\[U(s) = e^{iKs}\]

\section{Antiunitary operators}
\begin{newdef}[Antiunitary operator]
In mathematics, an antiunitary transformation, is a bijective antilinear map
\[U:H_{1}\to H_{2}\,\]
between two complex Hilbert spaces such that
\[\langle Ux,Uy\rangle ={\overline {\langle x,y\rangle }}\]
for all $x$ and $y$ y in $H_{1}$, where the horizontal bar represents the complex conjugate. If additionally one has $H_{1}=H_{2}$ then $U$ is called an antiunitary operator.
\end{newdef}

\begin{newprop}
\begin{enumerate}
\item $\langle Ux,Uy\rangle =\overline {\langle x,y\rangle }=\langle y,x\rangle$ holds for all elements $x, y$ of the Hilbert space and an antiunitary $U$.
\item When $U$ is antiunitary then $U^{2}$ is unitary. This follows from
\[ \langle U^{2}x,U^{2}y\rangle =\overline {\langle Ux,Uy\rangle }=\langle x,y\rangle\]
\item For unitary operator $V$ the operator $VK$, where $K$ is complex conjugate operator, is antiunitary. The reverse is also true, for antiunitary $U$ the operator $UK$ is unitary.
\item For antiunitary $U$ the definition of the adjoint operator $U^{*}$ is changed into
\[\langle U^{*}x,y\rangle =\overline {\langle x,Uy\rangle }\]
\item The adjoint of an antiunitary $U$ is also antiunitary and $UU^{*}=U^{*}U=1$.
\end{enumerate}
\end{newprop}

\chapter{Formulation of quantum mechanics}
\section{Axioms of quantum mechanics}
\begin{enumerate}
\item  The properties of a quantum system are completely defined by specification of its state vector $|\psi\rangle$. The state vector is an element of a complex Hilbert space $\mathcal{H}$ called the space of states.
\item With every physical property $A$ (energy, position, momentum, angular momentum, ...) there exists an associated linear, Hermitian operator $A$ (usually called observable), which acts in the space of states. The eigenvalues of the operator are the possible values of the physical properties.
\item 
\begin{itemize}
\item  If $|\psi\rangle$ is the vector representing the state of a system and if $|\phi\rangle$ represents another physical state, there exists a probability $P(|\psi\rangle,|\phi\rangle)$ of finding $|\psi\rangle$ in state $|\phi\rangle$, which is given by the squared modulus of the scalar product on $\mathcal{H}: \, P(|\psi\rangle,|\phi\rangle) = |\langle \psi | \phi \rangle|^2$ (Born Rule)
\item If $A$ is an observable with eigenvalues $a_k$ and eigenvectors $|k\rangle$, given a system in the state $|\psi\rangle$, the probability of obtaining $a_k$ as the outcome of the measurement of $A$ is $|\langle k | \psi \rangle|^2$. After the measurement
the system is left in the state projected on the subspace of the eigenvalue $a_k$ (Wave function collapse).
\end{itemize}
\item The evolution of a closed system is unitary. The state vector $|\psi(t)\rangle$ at time $t$ is derived from the state vector $|\psi(t_0)\rangle$ at time $t_0$ by applying a unitary operator $U(t,t_0)$, called the evolution operator: $\psi(t)\rangle = U(t,t_0) |\psi(t_0)\rangle$.
\end{enumerate}

\section{Transformations of States}
A transformation of states can be described by $|\psi\rangle \to U(\tau) | \psi \rangle \equiv | \psi' \rangle$. And we demand that
\[|\langle \phi | \psi \rangle| = |\langle \phi' | \psi' \rangle|\]
\begin{newthem}[Wigner Theorem]
Any mapping of the vector space onto itself that preserves the value of $|\langle \phi | \psi \rangle|$ may be implemented by an operator $U$ with $U$ being either unitary (linear) or antiunitary (antilinear).
\end{newthem}

\subsubsection{Continuous transformation} 
Only linear operators can describe continuous transformations because every continuous transformation has a square root. Suppose, for example, that $U(l)$ describes a displacement through the distance $l$. This can be done by two displacements of $U(l/2)$, and hence $U(l) = U(l/2) U(l/2)$. The product of two antilinear operators is linear, since the second complex conjugation nullifies the effect of the first. Thus, regardless of the linear or antilinear character of $U(l/2)$, it must be the case that $U(l)$ is linear. A continuous operator cannot change discontinuously from linear to antilinear as a function of $l$, so the operator must be linear for all $l$.

\subsubsection{Transformations of observables}
\noindent
For an observable $Q$, 
\[\langle \phi' | Q | \phi' \rangle = \langle \phi | U^{-1}QU | \phi \rangle \]
If $U(\tau)^{-1}QU(\tau) = \tau Q$, we can prove that
\[U|q\rangle = |\tau q\rangle\]
Here, $|q\rangle$ is the eigenvector of $Q$ with eigenvalue $q$. 


\section{Schr\"{o}dinger equation}
\noindent
$U(t,t_0)$ is unitary and $U(t_2,t_0) = U(t_2,t_1)U(t_1,t_0)$. We can define $H(t_0)$ as
\[\left. \frac{d}{dt}U(t,t_0)\right|_{t=t_0} = -iH(t_0) \mbox{ with } H(t_0) = H(t_0)^{\dagger}\]
We can demonstrate that
\[\left. \frac{dU(t,t_0)}{dt}\right|_{t=t_1} = -iH(t_1)U(t_1,t_0) \]
The formal solution of the differential equation is
\[U(t,t_0) = I + (-i)^n \sum_{n=1}^{\infty} \int_{t_0}^{t}dt_1 \int_{t_0}^{t_1}dt_2 \cdots \int_{t_0}^{t_{n-1}} dt_n H(t_1)H(t_2)\cdots H(t_n)\]
Suppose that $T$ stands for time ordering, placing all operators evaluated at later times to the left, the above equation can be written as
\[U(t,t_0) = I + \frac{(-i)^n}{n!} \sum_{n=1}^{\infty} \int_{t_0}^{t}dt_1 \int_{t_0}^{t}dt_2 \cdots \int_{t_0}^{t} dt_n T\{H(t_1)H(t_2)\cdots H(t_n)\} \equiv \exp \left[ -i T\left\{ \int_{t_0}^{t} H(t')dt'\right\} \right] \]
If the Hamiltonian operator $H$ is time-dependent but the $H$'s at different times commute. The equation above can be simplified to
\[U(t,t_0) = \exp \left[ -i \int_{t_0}^{t} H(t')dt' \right] \]
If the $H$ is time-independent, then
\[U(t,t_0) = \exp \left[ -i H(t-t_0) \right] \]
Since $|\psi(t)\rangle = U(t,t_0) |\psi(t_0)\rangle$, we can derive the Schr\"{o}dinger equation
\[\frac{d |\psi(t)\rangle}{dt} = -iH(t) |\psi(t)\rangle\]
The expectation value of an observable $Q$ is $\langle \psi | Q | \psi \rangle$, denoted by $\langle Q \rangle$. We can then derive that
\[\frac{d\langle Q \rangle}{dt} = -i \left\{ \langle [Q,H] \rangle + \langle \frac{\partial Q}{\partial t} \rangle \right\}\]
This is called Ehrenfest's theorem. 

\section{Position operators}
\noindent
In three dimensional space, for a particle, we have three operators corresponding to the observations of its position in space, $\bm{X} = (X_1, X_2, X_3)$. If the particle has some other internal degrees of freedom, then $\bm{X}$ plus some other observables $S$'s will form  a complete commuting set of operators. The eigenstate state will be denoted by $| \bm{x},s \rangle$, satisfying that
\[X_i | \bm{x},s \rangle = x_i | \bm{x},s \rangle  \]
It describes a particle posited in $\bm{x}$ with internal state $s$. And we will normalize $| \bm{x},s \rangle $ by 
\[\langle \bm{x},s'| \bm{x},s \rangle = \delta_{ss'}\delta(\bm{x}-\bm{x}')\]

\section{Momentum operators and canonical quantization}
\noindent
Since $\bm{X}$ plus some other observables $S$'s form a complete commuting set of operators. So, the momentum operators can not be independent of them. Numerous experiments shows that the position and momentum of particles can not be measured simultaneously. So, we expect $[X,P] \neq 0$.
\paragraph{Guess} 
For a system which has a classical correspondence, the classical equation of motion of a particle is
\begin{eqnarray}
\dot{x} &=& [x,H_C(x,p,t)]_C \nonumber \\
\dot{p} &=& [p,H_C(x,p,t)]_C \nonumber
\end{eqnarray}
$[\quad]_C$ is the Poisson bracket in classical mechanics. In quantum mechanics,
\begin{eqnarray}
\frac{d\langle X \rangle}{dt} &=& -i \langle [X,H] \rangle \nonumber \\
\frac{d\langle P \rangle}{dt} &=& -i \langle [P,H] \rangle \nonumber
\end{eqnarray}
If we assume that the classical equation of motion of a particle is an approximation of quantum mechanics, we may expect
\[[\quad] = i [\quad]_C \]
Since the Poisson bracket in classical mechanics and commutation bracket in quantum mechanics have the same algebra structure. To get the right classical equation of motion of the particle, we demand that
\[[X_i,X_j] = 0 \quad [X_i,X_j] = 0 \quad [X_i,P_j] = i \delta_{ij}\]
and
\[H = H_C(X,P,t)\]
For a general system, we formally define momentum operator $\bm{P}$ by 
\[[X_i,P_j] = i \delta_{ij}\]
The form of $H$ can not be given as a priori, which can be specified only by the hints from classical theory and experiments.

\section{Momentum operators and translation of states}
\begin{newthem}
\[\exp(iG\lambda) A \exp(-iG\lambda) = A + i\lambda[G,A] + \cdots + \frac{i^n\lambda^n}{n!}[G,[G,[G,\cdots[G,A]]]\cdots]+\cdots\]
\end{newthem}
\noindent
Define $T(\bm{a}) \equiv e^{-i\bm{P \cdot a}}$
We can get
\[T(\bm{a})^{-1} \bm{X} T(\bm{a}) = \bm{X} + \bm{a}\]
\[T(\bm{a})|\bm{x}\rangle = |\bm{x}+\bm{a}\rangle\]
So, $T(\bm{a})$ is the space translation operator. 
Now, we can also define the momentum operator as the generator of space translation.

\section{Angular momentum operators and rotation of states}
\noindent
We define the angular momentum operators $\bm{J}$ as the generator of rotation.
\[R(\bm{\theta}) \equiv e^{-i\bm{J} \cdot \bm{n} \theta}\]
If the operator $\bm{M} = (M_1,M_2,M_3)$ is a vector in configuration space and can be rotated by $R$, then we can demonstrate that
\[[J_{i},M_{j}] = i \epsilon_{ijk}M_k\]
Especially, 
\[[J_i,J_j] = i\epsilon_{ijk}J_k\]

\subsubsection{Orbital angular momentum}
\noindent
Orbital angular momentum of a particle is defined as $\bm{L} = \bm{X} \times \bm{P}$. It is the generator of rotation of the position of the particle, since
\[[L_i,X_j] = i\epsilon_{ijk}X_k \quad [L_i,P_j] = i\epsilon_{ijk}P_k \quad [L_i,L_j] = i\epsilon_{ijk}L_k\]

\subsubsection{Spin angular momentum}
\noindent
Experiments show that some microscopic particles possess a property called spin. The state of the spin is denoted by $|s\rangle$. The corresponding operators are $\bm{S} = [S_1,S_2,S_3]$, which measure the spin along the $\bm{1},\bm{2},\bm{3}$ direction. Spin operator is the generator of rotation of the spin of the particle, so we have
\[[S_i,S_j]=i\epsilon_{ijk}S_k\]
And the rotation of position and spin is independent, so
\[[S_i,L_j] = 0\]

\subsubsection{Total angular momentum}
\noindent
The total angular momentum of the particle is 
\[\bm{J} = \bm{L} + \bm{S}\]
It is the generator of the rotation of the entire system, which is equivalent to the rotation of the coordinates in opposite direction.

\section{Heisenberg picture}
\noindent
Define
\[Q_H = U^{\dagger}(t,t_0)QU(t,t_0)\]
We can derive that
\[\frac{dQ_H(t)}{dt} = -i[Q_H(t),H_H(t)] + \left(\frac{\partial Q}{\partial t}\right)_H \]
Here, $H_H(t) = U^{\dagger}(t,t_0) H(t) U(t,t_0)$
If the state of the system at $t_0$ is $|\phi_0\rangle$, then
\[\langle Q \rangle_t = \langle \phi(t) | Q | \phi(t) \rangle = \langle \phi_0 | Q_H(t) | \phi_0 \rangle\]
If the state $|q\rangle$ is the eigenstate of the $Q$ with the eigenvalue $q$, then $U^{\dagger}(t,t_0)|q\rangle$ is the eigenstate of the $Q_H$ with eigenvalue $q$, which can be denoted by $|q_H(t)\rangle$, so we have
\[\langle q | \phi(t) \rangle = \langle q_H(t) | \phi_0 \rangle\]

\section{Symmetries and conservation laws}
\noindent
Let $U = e^{iKs}$ be a continuous unitary transformation with generator$K=K^{\dagger}$. To say that the Hamiltonian
operator $H$ is invariant under this transformation means that
\[U(s)^{-1} H(t) U(s) = H(t)\]
Then we can deduce that
\[[K,H(t)] = 0\]
Usually, $K$ does not depend on time explicitly. If the above equation hold for all $t$, then in Heisenberg picture, 
\[K_H(t) = K \quad |k_H(t) \rangle = | k \rangle\]
So, 
\[\langle K \rangle_t = \langle K \rangle_{t_0} \quad \langle k | \phi(t) \rangle = \langle k | \phi_0 \rangle\]
The probability distribution of the measurement of the observable $K$ will not change with time for an arbitrary initial state. We can assume that the $K$ is a constant of motion.

\begin{note}
The concept of a constant of motion should not be confused with the
concept of a stationary state. \\
Suppose that the Hamiltonian operator $H$ is independent of $t$, and that the initial state vector is an eigenvector of $H$, $|\phi_0\rangle = | E_n \rangle$ with $H |E_n\rangle = E_n | E_n \rangle$. This describes a state having a unique value of energy $E_n$. So
\[|\phi(t)\rangle = e^{-iE_nt} |\phi_0\rangle\]
From this result it follows that the average of any dynamical variable $R$,
\[\langle \phi(t) | R | \phi(t) \rangle = \langle E_n | R | E_n \rangle\]
is independent of $t$ for such a state. By considering functions of $R$ we can further show that the probability distribution is independent of time. In a stationary state the averages and probabilities of all dynamical variables are independent of time, whereas a constant of motion has its average and probabilities independent of time for all states.
\end{note}
\chapter{Coordinate and Momentum Representation}
\section{Coordinate representation}
To form a representation of an abstract linear vector space, one chooses a complete orthonormal set of basis vectors $\{|u_i\rangle\}$ and represents an arbitrary vector $|\psi\rangle$ by its expansion coefficients $\{c_i\}$, where $|\psi\rangle = \sum c_i |u_i\rangle$. 
The array of coefficients $\langle u_i | \psi \rangle$ can be regarded as a column vector (possibly of infinite dimension), provided the basis set is discrete.\\
Coordinate representation is obtained by choosing as the basis set the eigenvectors $\{|\bm{x}\rangle\}$ of the position operator . Since this is a continuous set, the expansion coefficients define a function of a continuous variable,
\[\psi(\bm{x})  \equiv \langle \bm{x} | \psi \rangle\]
We can show that the inner product of the state vector in coordinate representation is
\[\langle \phi | \psi \rangle = \int \phi^{*}(\bm{x})\psi(\bm{x}) d^3\bm{x} \]
It is a matter of taste whether one says that the set of functions forms a representation of the vector space, or that the vector space consists of the functions $\psi(\bm{x})$.\\
The action of an operator $A$ on the function space is related to its action on the abstract vector space by the rule
\[A \psi(\bm{x}) \equiv  \langle \bm{x} |A| \psi \rangle\]
The action of an position operator in coordinate representation is
\[\bm{X}\psi(\bm{x}) = \bm{x} \psi(\bm{x})\]
The action of an momentum operator in coordinate representation is
\[\bm{P}\psi(\bm{x}) = -i \bm{\nabla}\psi(\bm{x})\]
For a spin-less particle in the scalar potential $W(\bm{x})$,
$H = \frac{\bm{P}^2}{2M} + W(\bm{X})$. 
The equation of motion in the coordinate representation is
\[ \left[- \frac{1}{2M} \bm{\nabla}^2 + W(\bm{x}) \right] \psi(\bm{x},t) = i\frac{\partial}{\partial t}\psi(\bm{x},t)\]

\section{Galilei transformation of Schr\"{o}dinger equation}
For simplicity we shall treat only one spatial dimension. Let us consider two frames of reference: $F$ with coordinates $x$ and $t$, and $F'$ with coordinates $x'$ and $t'$. $F'$ is moving uniformly with velocity $v$ relative to $F$, so that
\[x = x' + vt' \quad t=t'\]
The potential energy is given by $W(x,t)$ in $F$ , and by $W'(x',t')$ in $F'$, with
\[W(x,t) = W'(x',t')\]
Because the requirement of invariance under Galilei transformation, we expect in $F'$ the  Schr\"{o}dinger equation has the form
\[ \left[- \frac{1}{2M} \frac{\partial^2}{\partial x'^2} + W'(x') \right] \psi'(x',t') = i\frac{\partial}{\partial t'}\psi'(x',t')\]
where $\psi'(x',t')$ is the wave function in $F'$.
The probability density at a point in space–time must be the same in the two frames of reference
\[|\psi(x,t)|^2 = |\psi'(x',t')|^2\]
and hence we must have
\[\psi(x,t) = e^{if}\psi'(x',t')\]
where $f$ is a real function of the coordinates.
Put all the conditions above together, we can derive
\[f(x,t) = Mvx - \frac{1}{2} Mv^2t\]
apart from an irrelevant constant term.

\section{Probability flux and conditions on wave functions}
\noindent
Define the probability flux vector
\[\bm{J}(\bm{x},t) = \frac{1}{M} \mathrm{Im}(\psi^*\bm{\nabla}\psi)\]
We can get a continuity equation
\[\frac{d}{dt} |\psi(\bm{x},t)|^2 + \bm{\nabla} \cdot \bm{J}(\bm{x},t) = 0\]
Applying the divergence theorem, we obtain
\[\frac{\partial}{\partial t} \int_{\Omega} |\psi(\bm{x},t)|^2 d^3x = - \oint_{\sigma} \bm{J} \cdot d\bm{s}\]
The equations of continuity require that the probability
flux $\bm{J}(\bm{x},t)$ be continuous across any surface, since otherwise the surface would contain sources or sinks. Although this condition applies to all surfaces, implying that $\bm{J}(\bm{x},t)$ must be everywhere continuous, its practical applications are mainly to surfaces separating regions in which the potential has different analytic forms.
Usually, we have the following conditions,
\begin{enumerate}
\item \[\psi(x)|_{x+0} = \psi(x)|_{x-0} \quad \frac{d\psi}{dx}|_{x+0} = \frac{d\psi}{dx}|_{x-0}\]
\item \[\psi(x)|_{x+0} = \psi(x)|_{x-0} = 0 \quad \frac{d\psi}{dx}|_{x+0} - \frac{d\psi}{dx}|_{x-0} \mbox{ is finite }\]
\end{enumerate}
\noindent
Consider next the behavior at a singular point, assumed for convenience to be the origin of coordinates. Let $S$ be a small sphere of radius $r$ surrounding the singularity. The probability that the particle is inside $S$ must be finite.
Suppose that $\psi = \frac{u}{r^{\alpha}}$, where $u$ is a smooth function that does not vanish at $r=0$. Then we must have $|\psi|^2 r^3$ convergent at the origin, which implies that $\alpha < \frac{3}{2}$.\\
The net outward flow through the surface $S$ is $F = \oint_{S} J \cdot dS$. It must vanish in the limit $r \to 0$, since otherwise the origin would be a point source or sink.
One has $\frac{\partial \psi}{\partial r} = r^{-\alpha} \frac{\partial u}{\partial r} - \alpha u r^{-\alpha-1}$. The second term does not contribute to the flux, so we obtain
\[F \propto r^{2-2\alpha}\]
where the integration is over solid angle. If the integral does not vanish, then we must have $\alpha <1$ in order for $F$ to vanish in the limit $r \to 0$. This is a stronger condition than that derived from the probability density. \\
Since $|\psi|^2$ is a probability density, it must vanish sufficiently rapidly at infinity so that its integral over all configuration space is convergent and equal to 1. \\
The conditions that we have discussed apply to wave functions $\psi(x)$ which represent physically realizable states, but they need not apply to the eigenfunctions of operators that represent observables. Those eigenfunctions, $\chi(x)$, which play the role of filter functions in computing probabilities, are only required to lie in the extended space, $\Phi^X$, of the rigged-Hilbert-space triplet. It has been suggested that $\psi(x)$ be restricted to the nuclear space $\Phi$, rather than merely to the Hilbert space $\mathcal{H}$. In many cases this would amount to requiring that $\psi(x)$ should vanish at infinity more rapidly than any inverse power of the distance. 

\section{Path integrals}
\begin{newthem}[Gaussian integration]
\[\int dx e^{-\frac{1}{2} ax^2 + Jx} = \left( \frac{2\pi}{a}\right)^{\frac{1}{2}} e^{\frac{J^2}{2a}}\]
\end{newthem}
The time evolution of a quantum state vector, $|\psi(t)\rangle = U(t,t_0)| \psi(t_0)\rangle$, can be regarded as the propagation of an amplitude in configuration space,
\[\psi(x,t) = \int G(x,t;x',t_0) \psi(x',t_0)dx'\]
where
\[G(x,t;x',t_0) = \langle x,t | U(t,t_0) | x',t_0 \rangle\]
is often called the propagator. \\
Making use of the multiplicative property of the time development operator, it follows that the propagator can be written as
\[G(x,t;x_0,t_0) = \int \cdots \int G(x,t;x_N,t_N) \cdots G(x_1,t_1;x_0,t_0) dx_N \cdots dx_1\]
The N-fold integration is equivalent to a sum over zigzag paths that connect the initial point $(x_0,t_0)$ to the final point $(x,t)$. If we now pass to the limit of $N \to \infty$ and $\Delta t = t_i - t_{i-1} \to 0$, we will have the propagator expressed as a sum (or, rather, as an integral) over all paths
that connect the initial point to the final point.
We can show that
\[\langle x | e^{-iH \Delta t} | x' \rangle = \sqrt{\frac{M}{2i\pi\Delta t}} \exp \left\{ i\left[ \frac{M(x-x')^2}{2\Delta t^2}   -V(x') \right] \Delta t \right\} \quad \Delta t \to 0 \]
So,
\[G(x,t;x_0,t_0) = \lim_{N \to \infty} \int \cdots \int \left(\frac{M}{2i\pi\Delta t}\right)^{\frac{N+1}{2}} \exp \left\{ i \sum_{j=0}^{N}\left[ \frac{M(x_{j+1}-x_{j})^2}{2\Delta t^2}   -V(x_{j+1}) \right] \Delta t \right\} dx_1 \cdots dx_N\]
The final result can be expressed as
\[G(x,t;x_0,t_0) = \int \mathcal{D}[x(\tau)] e^{iS[x(\tau)]}\]
Here, $S[x(\tau)]$ is the action associated with the path
\[S[x(\tau)] = \int_{x(\tau)} L(x,\dot{x}) d\tau\]
The integral is a functional integration over all paths $x(\tau)$ which connect the initial point $(x_0,t_0)$ to the final point $(x,t)$.\\
To conclude this section, let us generalize our path-integral formula to a more complicated systems. Consider a very general quantum system, described by arbitrary set of of coordinates $q_i$, conjugate momentum $p^i$, and Hamiltonian $H(q,p)$. 
We can show that
\[\langle q_{k+1} | e^{-i\epsilon H} | q_{k}\rangle = \left( \prod_i \int \frac{dp^i_k}{2\pi}\right) \exp \left[ -i\epsilon H \left( \frac{q_{k+1}+q_{k}}{2},p_k\right) \right] \exp \left[ i \sum_i p_k^i (q_{i,k+1} - q_{i,k})\right] \] 
so,
\[\langle q_{N} | U(t,t_0) | q_{0}\rangle = \left( \prod_{i,k} \int \frac{dp^i_k dq_{i,k}}{2\pi}\right) \exp \left[ i\sum_k \left( \sum_i p_k^i (q_{i,k+1} - q_{i,k})-\epsilon H \left( \frac{q_{k+1}+q_{k}}{2},p_k\right)\right) \right]\]
There is one momentum integral for each $k$ from $0$ to $N$, and on coordinate integral for each $k$ from $1$ to $N$.
The final result can be expressed as
\[\langle q_{N} | U(t,t_0) | q_{0}\rangle = \left( \prod_{i} \int \mathcal{D}q(t) \mathcal{D}p(t) \right) \exp \left[ i \int_0^T dt \left( \sum_i p^i \dot{q_i} - H \left( q,p\right)\right) \right]\]
where the functions $q(t)$ are constrained at the endpoints, but $p(t)$ are not. 
The details of this generalization can be found in  chapter 9.1 of \emph{An introduction to quantum field theory (M.E.Peskin \& D.V.Schroeder)}

\section{Momentum representation}
Momentum representation is obtained by choosing as the basis set the eigenvectors $\{|\bm{p}\rangle\}$ of the momentum operator. The orthonormality condition takes the form
\[\langle \bm{p} | \bm{p}' \rangle = \delta(\bm{p}-\bm{p}')\]
Then we can derive that
\[\langle \bm{x} | \bm{p} \rangle = \frac{1}{(2\pi)^{3/2}} e^{i\bm{p}\cdot\bm{x}}\]
and
\[\phi(\bm{p}) \equiv \langle \bm{p} | \psi \rangle = \frac{1}{(2\pi)^{3/2}} \int e^{-i\bm{p}\cdot\bm{x}} \langle \bm{x} | \psi \rangle d^3 x\]
The effect of position operator in momentum representation is
\[\bm{X}\phi(\bm{p}) = i\bm{\nabla} \phi(\bm{p})\]
\subsubsection{Bloch's Theorem}
A crystal is unchanged by translation through a vector displacement of the form
\[\bm{R}_n = n_1\bm{a}_1 + n_2\bm{a}_2 + n_3\bm{a}_3\]
where $n_1$, $n_2$ and $n_3$ are integers, and $\bm{a}_1$, $\bm{a}_2$ and $\bm{a}_2$ form the edges of a unit cell of the crystal. Corresponding to such a translation, there is a unitary operator, $U(\bm{R}_n) = \exp(-i\bm{P}\cdot \bm{R}_n)$, which leaves the Hamiltonian of the crystal invariant:
\[U^{-1}(\bm{R}_n) H U(\bm{R}_n) = H\]
These unitary operators for translations commute with each other, as well as with $H$, so there must exist a complete set of common eigenvectors for all of these operators,
\[H|\psi\rangle = E|\psi\rangle \quad U(\bm{R}_n)|\psi\rangle = c(\bm{R}_n)|\psi\rangle\]
By the composition relation of the translation operators, we can deduce that
\[c(\bm{R}_n) = \exp(-i\bm{p}\cdot\bm{R}_n)\]
So, in coordinate representation, we have
\[\psi(\bm{x} - \bm{R}_n) = U(\bm{R}_n) \psi(\bm{x}) = \exp(-i\bm{p}\cdot\bm{R}_n) \psi(\bm{x})\]
The vector $\bm{p}$ is called the Bloch wave vector of the state. If we expand a function of the Bloch form in a series of plane waves, 
\[\psi(\bm{x}) = \sum_{\bm{k}'} a(\bm{k}') e^{i\bm{k}'\cdot \bm{x}}\]
we can show that for all $\bm{R}_n$
\[\exp(i(\bm{k}' - \bm{k})\cdot \bm{R}_n) = 1 \]
So $\bm{G}_n \equiv \bm{k}' - \bm{k}$ is a vector of the reciprocal lattice. So, the expansion can be written as
\[\psi(\bm{x}) = \sum_{\bm{G}_m} a(\bm{k} + \bm{G}_m) e^{i(\bm{k} + \bm{G}_m)\cdot\bm{x}}\]

\section{Harmonic oscillator}
A harmonic oscillator is an object that is subject to a quadratic potential energy, which produces a restoring force against any displacement from equilibrium that is proportional to the displacement. The Hamiltonian for such an object whose motion is confined to one dimension is
\[H = \frac{1}{2M}P^2 + \frac{M\omega^2}{2}Q^2\]
where $P$ is the momentum, $Q$ is the position, and $M$ is the mass.
\subsection{Algebraic solution}
We have the commutation relation
\[[Q,P] = i\]
and the self-adjointness of the operators $P$ and $Q$,
\[P = P^{\dagger} \quad Q = Q^{\dagger}\]
Define
\[ p \equiv (M\omega)^{-1/2}P \quad q \equiv (M\omega)^{1/2}Q\]
So
\[[q,p] = i \quad H = \frac{1}{2}\omega(p^2+q^2)\]
We further define
\[a \equiv \frac{q+ip}{\sqrt{2}}\]
We can verify that
\[[a,a^{\dagger}] = 1 \quad H = \frac{1}{2}\omega(aa^{\dagger}+a^{\dagger}a) = \omega(aa^{\dagger}-\frac{1}{2}) = \omega(a^{\dagger}a+\frac{1}{2})\]
Introduce $N \equiv a^{\dagger}a$, we have
\[[N,a] = -a \quad [N,a^{\dagger} = a^{\dagger}]\]
Let $N|\nu\rangle = \nu|\nu\rangle $, with $\langle \nu | \nu \rangle \neq 1$. We have
\[Na|\nu\rangle = a(N-1)|\nu\rangle = (\nu-1)a|\nu\rangle\]
If $\nu \neq 0$, then $a|\nu\rangle$ cannot be $0$, $a|\nu\rangle$ must be an eigenvector of $N$ with eigenvalue $\nu - 1$.
On the other hand, we have
\[(\langle \nu | a^{\dagger})(a|\nu\rangle) = \langle \nu | N | \nu \rangle = \nu \langle \nu | \nu \rangle\]
Since the norm must be nonnegative, it follows that $\nu \geq 0$, and thus an eigenvalue cannot be negative. By applying the operator a repeatedly, it would appear that one could construct an indefinitely long sequence of eigenvectors
having the eigenvalues $\nu-1$, $\nu-2$, $\nu-3$ and so on.
The contradiction can be avoided only if the sequence terminates with the value $\nu=0$ and $a|0\rangle = 0$.\\
We also have that
\[Na^{\dagger}|\nu\rangle = a^{\dagger}(N+1)|\nu\rangle = (\nu+1)a^{\dagger}|\nu\rangle\]
The squared norm of the vector $a^{\dagger} |\nu\rangle$ is
\[(\langle \nu | a)(a^{\dagger} | \nu \rangle)= \langle \nu | N+1|\nu\rangle = (\nu+1) \langle \nu | \nu \rangle \]
which never vanishes because $\nu \geq 0$. Thus $a^{\dagger} | \nu \rangle$ is an eigenvector of $N$ with eigenvalue $\nu+1$. By repeatedly applying the operator $a^{\dagger}$, one can construct an unlimited sequence of eigenvectors, each having an eigenvalue one unit greater than that of its predecessor. The sequence begins with the eigenvalue $\nu=0$.
Therefore the spectrum of $N$ consists of the nonnegative integers, $\nu=n$. \\
The orthonormal eigenvectors of $N$ will be denoted as $|n\rangle$, and we can verify that
\[ |n\rangle = n^{-1/2} a^{\dagger} |n-1\rangle = (n!)^{-1/2} (a^{\dagger})^n |0\rangle\]
The matrix elements of $a^{\dagger}$ and $a$ are
\[\langle n' | a^{\dagger} |n \rangle = (n+1)^{1/2}\delta_{n',n+1} \quad  \langle n' | a |n \rangle = (n)^{1/2}\delta_{n',n-1}\]
Finally we note that the eigenvalues and eigenvectors of the harmonic oscillator Hamiltonian are
\[H |n\rangle = E_n |n\rangle \quad  E_n =(n+\frac{1}{2})\omega\]

\subsection{Solution in coordinate representation}
In the coordinate representation, we have
\[-\frac{1}{2M} \frac{d^2}{dx^2} \psi(x) + \frac{M\omega^2}{2}x^2 \psi(x) = E \psi(x)\]
Define
\[q \equiv (M\omega)^{1/2}x \quad \lambda \equiv \frac{2E}{\omega}\]
The differential equation becomes
\[\frac{d^2u}{dq^2} + (\lambda - q^2)u = 0\]
When $q \to \pm \infty$, we have $u(q) \sim e^{q^2/2}$ or $e^{-q^2/2}$. The first of these is unacceptable, because it
diverges so severely as to be outside of both Hilbert space and rigged Hilbert space. We would seek solutions of the form 
\[u(q) = H(q) e^{-\frac{1}{2}q^2}\]
We then have
\[H'' - 2qH' + (\lambda-1)H = 0\]
It is the so-called \href{http://mathworld.wolfram.com/HermiteDifferentialEquation.html}{\textbf{Hermite differential equation}}. When $\lambda - 1 = 2n$, we have regular solutions. Solutions are \href{http://mathworld.wolfram.com/HermitePolynomial.html}{Hermite polynomials}, and will be denoted as $H_n(q)$. After appropriate normalization, we have
\[\psi_n(x) = \left [ \frac{\alpha}{\pi^{1/2} 2^n n!} \right ]^{1/2} H_n(\alpha x) e^{-\frac{1}{2}\alpha^2 x^2} \quad E_n = (n+\frac{1}{2})\omega\]
where $\alpha \equiv (M\omega)^{1/2}$.

\subsection{Path integral solution}
The propagator of harmonic oscillator in terms of path integral are
\begin{eqnarray}
G(x_b,t_b;x_a,t_a) &=& \int \mathcal{D}[x(t)] e^{i\int_{t_a}^{t_b} (\frac{1}{2}M\dot{x}^2 - \frac{1}{2}M\omega^2 x^2)dt} \nonumber \\
&=& \lim_{N \to \infty} \int \left(\frac{M}{2i\pi\Delta t}\right)^{\frac{N+1}{2}} \exp \left\{ i \sum_{j=0}^{N}\left[ \frac{M(x_{j+1}-x_{j})^2}{2\Delta t^2}   - \frac{1}{2}M\omega^2 x_{j+1}^2 \right] \Delta t \right\} dx_1 \cdots dx_N \nonumber
\end{eqnarray}
where
\[x_0 = x_a \quad x_{N+1} = x_b \quad \Delta t = \frac{t_b-t_a}{N+1}\]
Suppose $x_c(t)$ is the classical path of harmonic oscillator and we define
\[\delta x(t) \equiv x(t) - x_c(t)\]
Substitute it into the equation above, the terms which is linear in $\delta x$ can be dropped, because
\[\frac{\delta S}{\delta x} |_{x(t) = x_c(t)}\]
And since $x_c(t_a) = x_a$, $x_c(t_b) = x_b$, we have
\[\delta x_{0} = \delta x_{N+1} = 0\]
At last, we have
\begin{eqnarray}
G(x_b,t_b;x_a,t_a) &=& e^{iS_c} \lim_{N \to \infty} \int \left(\frac{M}{2i\pi\Delta t}\right)^{\frac{N+1}{2}} \exp \left\{ i \sum_{j=1,k=1}^{N} \delta x_j S_{jk} \delta x_k\right\} d\delta x_1 \cdots d\delta x_N \nonumber \\
&=& e^{iS_c} \lim_{N \to \infty} \left(\frac{M}{2i\pi\Delta t}\right)^{\frac{N+1}{2}} \sqrt{\frac{\pi^N}{\det (-iS)}}
\end{eqnarray}
where
\[-iS = \frac{M}{2i\Delta t} \left( \begin{matrix} 2-\omega^2\Delta t^2 & -1& 0& \ldots \\ -1& 2-\omega^2\Delta t^2& -1& \ldots \\ 0& -1& 2-\omega^2\Delta t^2& \ldots \\ \vdots & \vdots & \vdots & \end{matrix} \right)\]
The details of the following calculation will be eliminated here, and some discussion can be found in section 2.1.4 of \emph{Quantum Field Theory of Many-body Systems (Xiao-Gang Wen)}. The final result is\\
\[G(x_b,t;x_a,0) = \left ( \frac{M\omega}{2\pi i \sin \omega t} \right )^{1/2}\exp \left [ \frac{iM\omega}{2\sin\omega t} \left ((x_a^2 + x_b^2)\cos\omega t - 2x_a x_b  \right ) \right ]\]
In the limit $\omega \to 0$, we have
\[G(x_b,t;x_a,0) = \left ( \frac{M}{2\pi i t} \right )^{1/2}\exp \left [ \frac{iM}{2t} \left ( x_b-x_a\right)^2 \right ]\]
This is just the propagator of free particle.

\chapter{Angular Momentum}
\section{Eigenvalues of angular momentum operator}
The commutation relations among the angular momentum operators are
\[[J_i,J_j] = \epsilon_{ijk} J_k\]
And these three operators are self-adjoint. We first introduce the operator $J^2 = J_x^2 + J_y^2 + J_z^2$. We can verify that $[J^2,\bm{J}] = 0$. Thus there exists a complete set of common eigenvectors of $J^2$ and any one component of $\bm{J}$. Particularly, we have the pair of eigenvalue equations
\[J^2 | \beta,m\rangle = \beta | \beta,m\rangle \quad J_z | \beta,m\rangle = m | \beta,m\rangle\]
Since
\[\langle \beta,m | J^2 | \beta,m \rangle = \langle \beta,m | J_x^2 | \beta,m \rangle + \langle \beta,m | J_y^2 | \beta,m \rangle + \langle \beta,m | J_z^2 | \beta,m \rangle\]
we have $m^2 \leq \beta$. Thus for a fixed value of $\beta$ there must be maximum and minimum values for $m$.\\
Define
\[J_+ \equiv J_x + iJ_y \quad J_- \equiv J_x - iJ_y\]
we have the commutation relations
\[[J_z,J_+] = J_+ \quad [J_z,J_-] = -J_- \quad [J_+,J_-] = 2J_z\]
So
\[J_z J_+ | \beta,m\rangle = J_+(J_z + 1)| \beta,m\rangle = (m+1)J_+| \beta,m\rangle\]
Therefore, either $J_+ | \beta,m\rangle$ is an eigenvector of $J_z$ with the raised eigenvalue $m+1$, or $J_+ | \beta,m\rangle = 0$. Now for fixed $\beta$ there is a maximum value of $m$, which we shall denote as $j$. It must be the case that
\[J_+ |\beta,j\rangle = 0\]
Since
\[J_+ J_- = J^2 - J_z^2 - J_z\]
it is obvious that $\beta = j(j+1)$. By similar method, we can show the minimum eigenvalue of $J_z$ for fixed $\beta$ satisfy that $\beta = k(k-1)$. So, we have $k = -j$. \\
We have thus shown the existence of a set of eigenvectors corresponding to integer spaced $m$ values in the range $-j \leq m \leq j$. Since the difference between the maximum value $j$ and the minimum value $-j$ must be an integer, it follows that $j = \mbox{ integer} / 2$. Henceforth we shall adopt the common and more convenient notation of labeling the eigenvectors by $j$ instead of by $\beta$. Thus the vector that was previously denoted as $|\beta,m\rangle$ will now be denoted as $|j,m\rangle$. 

\section{Orbital Angular Momentum and Spin}
Let $\psi(\bm{x})$ be a one-component state function in coordinate representation. When it is subjected to a rotation it is transformed into
\[\bm{R}\psi(\bm{x}) = \psi(R^{-1}\bm{x})\]
where $\bm{R}$ is the rotation operator generated by $\bm{R} = \exp(-i\bm{J}\cdot\bm{n}\theta)$. For a rotation through infinitesimal angle $\epsilon$ about the $z$ axis, we have
\[\bm{R}_z(\epsilon) \psi(x,y,z) = \psi(x+\epsilon y,y-\epsilon x,z) = \psi(x,y,x) + \epsilon (y \frac{\partial \psi}{\partial x} - x \frac{\partial \psi}{\partial y})\]
On the other hand, 
\[\bm{R}_z(\epsilon) = I - i\epsilon J_z\]
so, we have $J_z = -i(x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x})$. This is just the $z$ component of the orbital angular momentum operator $L = \bm{X} \times \bm{P}$.\\
For a multicomponent state function, we have
\[\bm{R} \left( \begin{matrix} \psi_1(\bm{x}) \\ \psi_2(\bm{x}) \\  \vdots \end{matrix} \right) = D \left( \begin{matrix} \psi_1(R^{-1}\bm{x}) \\ \psi_2(R^{-1}\bm{x}) \\  \vdots \end{matrix} \right)\]
Thus the general form of the rotation operator will be
\[\bm{R}_{n}(\theta) = e^{-i\bm{L}\cdot\bm{n}\theta}D_n(\theta)\]
The two factors commute because the first acts only on the coordinate and the second acts only on the components of the column vector. The matrix $D$ must be unitary, and so it can be written as
\[D_n(\theta) = e^{-i\bm{S}\cdot\bm{n}\theta}\]
The angular momentum operator $\bm{J}$ has the form
\[\bm{J} = \bm{L} + \bm{S}\]
with $\bm{L} = \bm{X} \times \bm{P}$ and $[L_{\alpha},S_{\beta}] = 0$. In the particular representation used in this section, we have $\bm{L} = -i\bm{x}\times\bm{\nabla}$, and the components of $S$ are
discrete matrices. The operators $\bm{L}$ and $\bm{S}$ are called the orbital and spin parts of the angular momentum.
\subsubsection{Orbital angular momentum}
The form of the gradient operator in spherical coordinates is
\[\bm{\nabla} = \bm{e}_r \frac{\partial}{\partial r} + \bm{e}_{\theta} \frac{1}{r} \frac{\partial}{\partial \theta} + \bm{e}_{\phi} \frac{1}{r\sin\theta} \frac{\partial}{\partial \phi}\]
The orbital angular momentum operator then has the form
\[\bm{L} = r\bm{e}_r \times (-i\bm{\nabla}) = (-i) \left[ \bm{e}_{\phi} \frac{\partial}{\partial \theta} - \bm{e}_{\theta} \frac{1}{\sin\theta} \frac{\partial}{\partial \phi} \right]\]
So,we have
\[L_z = \bm{L}\cdot\bm{e}_z = -i\frac{\partial}{\partial \phi}\]
\[L^2 = \bm{L}\cdot\bm{L} = - \left [ \frac{1}{\sin\theta} \frac{\partial }{\partial \theta} (\sin\theta \frac{\partial }{\partial \theta}) + \frac{1}{\sin^2\theta} \frac{\partial^2}{\partial \phi^2}  \right ]\]
We must now solve the two coupled differential equations,
\[L_z Y(\theta,\phi) = m Y(\theta,\phi) \quad L^2 Y(\theta,\phi) = l(l+1) Y(\theta,\phi)\]
Apart from normalization, we have $Y(\theta,\phi) = e^{im\phi}P_l^m(\cos\theta)$. Here, $P_l^m$ is the \href{https://en.wikipedia.org/wiki/Associated_Legendre_polynomials}{associated Legendre polynomials}. If we assume that the solution must be single-valued under rotation, then it will follow that $m$ must be an integer. If we further assume that it must be nonsingular at $\theta = 0$ and $\theta = \pi$, then from the standard theory of the Legendre equation it will follow that $l$ must be a nonnegative integer in the range $l \geq |m|$. The normalized solutions that result from these assumptions are the well-known \href{https://en.wikipedia.org/wiki/Spherical_harmonics}{spherical harmonics}
\[Y_l^m(\theta,\phi) = (-1)^{(m+|m|)/2} \left [\frac{(2l+1)(l-|m|)!}{4\pi(l+|m|)!}  \right ]^{1/2}e^{im\phi} P_l^{|m|}(\cos\theta)\]
\subsubsection{Spin}
A particular species of particle is characterized by a set of quantum numbers that includes the value of its spin s, it is often sufficient to treat the spin operators $\bm{S}$ as acting on the space of dimension
$2s+1$ that is spanned by the eigenvectors of for a fixed value of $s$. \\
If $s= \frac{1}{2}$, we have
\[S_x = \frac{1}{2} \left[ \begin{matrix} 0& 1\\ 1& 0\end{matrix} \right] \quad S_y = \frac{1}{2} \left[ \begin{matrix} 0& -i\\ i& 0\end{matrix} \right] \quad S_z = \frac{1}{2} \left[ \begin{matrix} 1& 0\\ 0& -1\end{matrix} \right]\]
The spin operator in direction $\bm{n} = (\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)$ is
\[\bm{S}_{n} = \frac{1}{2} \left[ \begin{matrix} \cos\theta& e^{-i\phi}\sin\theta\\ e^{i\phi}\sin\theta& -\cos\theta\end{matrix} \right]\]
The eigenvectors are
\[\left[ \begin{matrix} e^{-i\phi/2}\cos\frac{\theta}{2}\\ e^{i\phi/2}\sin\frac{\theta}{2} \end{matrix} \right] \quad \left[ \begin{matrix} -e^{-i\phi/2}\sin\frac{\theta}{2}\\ e^{i\phi/2}\cos\frac{\theta}{2} \end{matrix} \right]\]
corresponding to eigenvalues $\frac{1}{2}$ and $-\frac{1}{2}$.\\
If $s= 1$, we have
\[S_x = \sqrt{\frac{1}{2}} \left[ \begin{matrix} 0& 1& 0\\ 1& 0& 1\\ 0& 1& 0\end{matrix} \right]  \quad S_y = \sqrt{\frac{1}{2}} \left[ \begin{matrix} 0& -i& 0\\ i& 0& -i\\ 0& i& 0\end{matrix} \right] \quad S_z = \sqrt{\frac{1}{2}} \left[ \begin{matrix} 1& 0& 0\\ 0& 0& 0\\ 0& 0& -1\end{matrix} \right]\]
The spin operator in direction $\bm{n} = (\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)$ is
\[\bm{S}_{n} =  \left[ \begin{matrix} \cos\theta& \sin\theta e^{-i\phi} \sqrt{\frac{1}{2}}& 0\\ \sin\theta e^{i\phi}\sqrt{\frac{1}{2}}& 0& \sin\theta e^{-i\phi} \sqrt{\frac{1}{2}}\\ 0& \sin\theta e^{i\phi} \sqrt{\frac{1}{2}}& -\cos\theta\end{matrix} \right]\]
The eigenvectors are
\[\left[ \begin{matrix} \frac{1}{2}(1+\cos\theta)e^{-i\phi}\\ \sqrt{\frac{1}{2}}\sin\theta \\ \frac{1}{2}(1-\cos\theta)e^{i\phi} \end{matrix} \right] \quad \left[ \begin{matrix} -\sqrt{\frac{1}{2}}\sin\theta e^{-i\phi}\\ \cos\theta \\ \sqrt{\frac{1}{2}}\sin\theta e^{i\phi} \end{matrix} \right] \quad \left[ \begin{matrix} \frac{1}{2}(1-\cos\theta)e^{-i\phi}\\ -\sqrt{\frac{1}{2}}\sin\theta \\ \frac{1}{2}(1+\cos\theta)e^{i\phi} \end{matrix} \right]\]
corresponding to eigenvalues $1$, $0$ and $-1$.

\section{Rotation operator}

\section{Addition of angular momentum}

\section{Hydrogen atom}

\chapter{Charged Particle in a Magnetic Field}

\chapter{Discrete Symmetries}

\chapter{Approximation method}
\section{Time independent perturbation theory}
\section{Time dependent perturbation theory}
\section{Atomic Radiation}
\section{The classical limit}

\chapter{Many body problem}
\section{Identical particles}
\section{Non-relativistic quantum field theory}

\chapter{Scattering theory}
\section{Lippmann–Schwinger equation}
Imagine a particle coming in and getting scattered by a short-ranged potential $V(x)$ located around the origin $x \sim 0$. The time-independent Schr\"{o}dinger equation is simply
\[(H_0 + V)|\psi\rangle = E |\psi\rangle\]
Here, $H_0 = \frac{p^2}{2m}$ is the free-particle Hamiltonian operator. We can write the solution as
\[|\psi^{(\pm)}\rangle = \frac{1}{E-H_0 \pm i\epsilon}V|\psi^{(\pm)}\rangle + |\phi\rangle\]
Here, $H_0 |\phi\rangle = E |\phi\rangle$. In coordinate representation,
\[\psi^{(\pm)}(\mathbf{x}) = \phi(\mathbf{x}) + \int d^3x' \langle \mathbf{x} | \frac{1}{E-H_0 \pm i\epsilon} | \mathbf{x}' \rangle V(\mathbf{x}') \psi^{(\pm)}(\mathbf{x}')\]
Here, $\phi(\mathbf{x}) = \frac{e^{i\mathbf{k}\cdot\mathbf{x}}}{(2\pi)^{\frac{3}{2}}}$. Define the Green function as
\[G_{\pm}(\mathbf{x},\mathbf{x}') \equiv \frac{1}{2m} \langle \mathbf{x} | \frac{1}{E-H_0 \pm i\epsilon} | \mathbf{x}' \rangle\]
We can derive that
\[G_{\pm}(\mathbf{x},\mathbf{x}') = -\frac{1}{4\pi} \frac{e^{\pm ik|\mathbf{x}-\mathbf{x}'|}}{|\mathbf{x}-\mathbf{x}'|}\]
where $k = \sqrt{2mE}$. And it is easy to show that
\[(\nabla^2 + k^2)G_{\pm}(\mathbf{x},\mathbf{x}') = \delta(\mathbf{x}-\mathbf{x}')\]
So, we have
\[\psi^{(\pm)}(\mathbf{x}) = \frac{e^{i\mathbf{k}\cdot\mathbf{x}}}{(2\pi)^{\frac{3}{2}}} - 2m \int d^3x' \frac{1}{4\pi} \frac{e^{\pm ik|\mathbf{x}-\mathbf{x}'|}}{|\mathbf{x}-\mathbf{x}'|} V(\mathbf{x}') \psi^{(\pm)}(\mathbf{x}')\]
We now can interpret $\psi^{+}(\mathbf{x})$ as a superposition of incident plane wave and scattered wave which propagate from scatterer to outside region. From now on, we will denote it as $\psi(\mathbf{x})$.

The experiment is done typically by placing the detector far away from the scatterer $|\mathbf{x}| \ll a$ where $a$ is the "size" of the scatterer. The integration over $\mathbf{x}'$, on the other hand, is limited within the "size" of the scatterer because of the $V(\mathbf{x}')$ factor. Therefore, we are in the situation $|\mathbf{x}| \ll |\mathbf{x}'|$, and hence can use the approximation
\[|\mathbf{x}-\mathbf{x}'| \approx |\mathbf{x}| - \frac{\mathbf{x}' \cdot \mathbf{x}}{|\mathbf{x}|}\]
Under this limit,
\[\psi(\mathbf{x}) = \frac{e^{i\mathbf{k}\cdot\mathbf{x}}}{(2\pi)^{\frac{3}{2}}} - 2m \frac{e^{ikr}}{4\pi r} \int d^3x' e^{-\mathbf{k}' \cdot \mathbf{x}'} V(\mathbf{x}') \psi(\mathbf{x}')\]
Here, $r = |\mathbf{x}|$ and $\mathbf{k}' = k \frac{\mathbf{x}}{r}$. It is customary to write this equation in the form
\[\psi(\mathbf{x}) = \frac{1}{(2\pi)^{\frac{3}{2}}}\left( e^{i\mathbf{k}\cdot\mathbf{x}} +  f(\mathbf{k},\mathbf{k}') \frac{e^{ikr}}{r} \right) \]
Here,
\[f(\mathbf{k},\mathbf{k}') \equiv - \frac{m}{2\pi} (2\pi)^3  \langle \mathbf{k}'| V | \psi\rangle \]
Recall the definition of cross section
\[\sigma \equiv \frac{\mbox{Number of Events}}{\mbox{Time} \times \mbox{Incident Flux}}\]
So, the differential cross section for particles being scattered into the solid angle is
\[d\sigma = \frac{|\mathbf{j}_{\mathrm{scatt}}| r^2 d\Omega}{|\mathbf{j}_{\mathrm{inc}}|} = |f(\mathbf{k},\mathbf{k}')|^2 d\Omega\]

In a more realistic situation, we should use wave packets to describe the scattering process. The basic picture is a free wave packet approaches the scattering center. After a long time, we have both the original wave packet moving in the original direction plus a spherical wave front that moves outward. The details can be found in the section 3 of the lecture notes 
\href{http://hitoshi.berkeley.edu/221B/index.html}{\emph{Scattering Theory I (Hitoshi Murayama)}}.

Furthermore, if we require that the normalization of the wave function should always satisfy $\int dx^3 |\psi(\mathbf{x})|^2$ for any $t$, as guaranteed by the unitarity of time evolution operator. This requirement leads to a special requirement on the scattered wave, and hence $f(\mathbf{k},\mathbf{k}')$, from witch we can derive the optical theorem.

\begin{newthem}[Optical theorem]
\[\mathrm{Im} f(\theta = 0) = \frac{k\sigma_{\mathrm{tot}}}{4\pi}\]
where
\[f(\theta = 0) \equiv f(\mathbf{k},\mathbf{k}),\]
the setting of $\mathbf{k} \equiv \mathbf{k}'$ imposes scattering in the forward direction, and
\[\sigma_{\mathrm{tot}} = \int \frac{d\sigma}{d\Omega} d\Omega\]
\end{newthem}
The meaning of this theorem is clear. Because the scattered wave takes the probability away to different directions, the total probability for the particle to go to the forward direction (unscattered) should decrease. This decrease is caused by the interference between the unscattered and scattered waves and hence is proportional to $f(0)$. On the other hand, the amount of decrease in the forward direction should equal the total probability at other directions, which is proportional to the total cross section. The proof can be found in the section 4 of the lecture notes \href{http://hitoshi.berkeley.edu/221B/index.html}{\emph{Scattering Theory I (Hitoshi Murayama)}}.

\section{Born approximation}
If $|\psi\rangle = |\phi\rangle + O(V)$ is close to $|\phi\rangle$, we can solve the Lippmanmn-Schwinger equation by perturbation theory. The lowest order approximation in $V$ is
\[|\psi\rangle = \frac{1}{E-H_0 + i\epsilon} V|\phi\rangle + |\phi\rangle\]
This is called Born approximation. In coordinate representation,
\[f^{(1)}(\mathbf{k},\mathbf{k}') = - \frac{m}{2\pi} \int d^3x V(\mathbf{x}) e^{i\mathbf{q}\cdot\mathbf{x}}\]
Here, $\mathbf{q} = |\mathbf{k} - \mathbf{k}'|$. If the potential is central, we can derive that
\[f^{(1)}(\mathbf{k},\mathbf{k}') = - \frac{2m}{q} \int_0^{\infty} dr \: r V(r) \sin(qr)\]

\subsubsection{Yukawa potential}
\[V = \frac{\alpha}{r}  e^{-\mu r}\]
So, we can derive
\[f(\theta) = - \frac{2m\alpha}{q^2 + \mu^2}\]
Different cross section is therefore given by
\[\frac{d\sigma}{d\Omega} = (2m\alpha)^2 \frac{1}{[2k^2(1-\cos\theta) + \mu^2]^2}\]
The total cross section is obtained by integrating over $d\Omega$,
\[\sigma = (2m\alpha)^2 \frac{4\pi}{4k^2\mu^2 + \mu^4}\]

\subsubsection{Coulomb potential}
\[V = \frac{\alpha}{r}\]
Take the limit $\mu \to 0$, we can get
\[f(\theta) = - \frac{2m\alpha}{q^2}\]
Different cross section is given by
\[\frac{d\sigma}{d\Omega} = (\frac{\alpha}{4E})^2 \frac{1}{\sin^4{\frac{\theta}{2}}}\]
The total cross section diverges. The divergence is in the $\cos\theta$ integral when $\theta \to 0$. In other words, the divergence occurs for the small momentum transfer $q \to 0$, which corresponds to large distances.
The reason why the total cross section diverges is because the Coulomb potential is actually a long-range force. No matter how far the incident particles are from the charge, there is always an effect on the motion of the particles and they get scattered.

\subsubsection{Form factor}
\noindent
If the source of Coulomb potential has an distribution $\rho_N(\mathbf{x})$, then
\[V(\mathbf{x}) = \int d^3x \frac{\alpha}{|\mathbf{x}-\mathbf{x}'|} \rho(\mathbf{x}')\]
Note that the potential is mathematically a convolution of the Coulomb potential and the probability density. Since the first Born amplitude is nothing but the Fourier transform of the potential, the convolution becomes a product of Fourier transforms, one for the Coulomb potential and the other for the probability density. So
\[f(\theta) = f(\theta)_{\mathrm{pointlike}} F(q)\]
Here,
\[F(q) \equiv \int d^3x \rho_N(\mathbf{x}) e^{i \mathbf{q} \cdot \mathbf{x}},\]
being called form factor.

\subsubsection{Born expansion}
\noindent
Define T-matrix by
\[V | \psi \rangle = T |\phi\rangle\]
Using the definition of the T-matrix, we find
\[f(\mathbf{k},\mathbf{k}') = - \frac{m}{2\pi} (2\pi)^3  \langle \mathbf{k}'| T | \mathbf{k}\rangle \]
Using the Lippmann–Schwinger equation and multiplying the
both sides by $V$ from left, we find
\[ T |\phi\rangle = V \frac{1}{E-H_0 + i\epsilon}T|\phi\rangle + V|\phi\rangle\]
A formal solution to the T-matrix is
\[T = \frac{1}{1-V\frac{1}{E-H_0 + i\epsilon}}V\]
By Taylor expanding this operator in geometric series, we find
\[T = V + V \frac{1}{E-H_0 + i\epsilon} V + V \frac{1}{E-H_0 + i\epsilon} V \frac{1}{E-H_0 + i\epsilon} V + \cdots\]
So,
\[|\psi\rangle = \left( 1 +  \frac{1}{E-H_0 + i\epsilon} V +  \frac{1}{E-H_0 + i\epsilon} V \frac{1}{E-H_0 + i\epsilon} V + \cdots \right) | \phi \rangle\]
The first term is the wave which did not get scattered.
The second term is the wave that gets scattered at a point in the potential and then propagates outwards by the propagator. 
In the third term, the wave gets scattered at a point in the potential, propagates for a while, and gets scattered again at another point in the potential, and propagates outwards. 
In the $n+1$-th term, there are $n$ times scattering of the wave before it propagates outwards.

\section{Partial wave analysis}
\subsubsection{Partial wave expansion}
When the potential is \textbf{central}, angular momentum is conserved due to Noether's theorem. Therefore, we can expand the wave function in the eigenstates of the angular momentum. Obtained waves with definite angular momenta are called partial waves. We can solve the scattering problem for each partial wave separately, and then in the end put them together to obtain the full scattering amplitude.
The plane wave can be expanded as follows.
\[e^{ikz} = \sum_{l=0}^{\infty}(2l+1)i^l j_l(kr) P_l(\cos \theta)\]
Here, $j_l(kr)$ is spherical Bessel functions of first kind. The asymptotic behaviour of $j_l(kr)$ at large $r$ can be written as
\[j_l(kr) \sim \frac{\sin(kr-\frac{l\pi}{2})}{kr}\]
so,
\[e^{ikz} \sim \frac{1}{2ikr} \sum_{l=0}^{\infty} (2l+1) (e^{ikr} - (-1)^l e^{-ikr})P_l(\cos \theta)\]
Meanwhile, the $f$ factor can be expanded as
\[f(\theta) = \sum_{l=0}^{\infty} f_l (2l+1)P_l(\cos \theta)\]

\subsubsection{Optical theorem constraint}
\noindent
The cross section can be represented by expansion coefficient of $f$ factor as
\[\sigma = 4\pi \sum_l (2l+1)|f_l|^2\]
On the other hand, 
\[\mathrm{Im} f(0) = \sum_l (2l+1) \mathrm{Im} f_l\]
From optical theorem we can derive that
\[|f_l|^2 = \frac{1}{k} \mathrm{Im} f_l\]
This constraint can be rewritten as
\[|1+2ikf_l|^2 = 1\]
So we can define a phase $\delta_l$ as 
\[1+2ikf_l = e^{i\delta_l}\]
or equivalently,
\[f_l = \frac{1}{k} e^{i\delta_l} \sin(\delta_l)\]

\subsubsection{Phase shifts}
\noindent
We can derive the asymptotic behaviour of the wave function as
\[\psi(\mathbf{x}) \sim \frac{1}{2ikr} \sum_{l} (2l+1)P_l(\cos \theta) [e^{ikr}e^{2i\delta_l} - (-1)^l e^{-ikr}]\]
Compare it to the case of the plane wave without scattering. What this equation says is that the wave converging on the scatterer
has the well-defined phase factor $-(-1)^l$, the same as in the case without scattering. On the other hand, the wave that emerges from the scatterer has an additional phase factor $e^{2i\delta_l}$. All what scattering did is to shift the phase of the emerging wave by $2\delta_l$. The reason why this is merely a phase factor is
the conservation of probability. What converged to the origin must come out with the same strength. But this shift in the phase causes the interference among all partial waves different from the case without the phase shifts, and the result is not a plane wave but contains the scattered wave.\\
In terms of the phase shifts, the cross section is given by
\[\sigma = \frac{4\pi}{k^2} \sum_l (2l+1) \sin^2\delta_l\]
Actual calculation of phase shifts is basically to solve the Schr\"{o}dinger equation for each partial waves,
\[\left[-\frac{1}{r}\frac{d^2}{dr^2}r+\frac{l(l+1)}{r^2}+2mV(r)\right]R_l(r) = k^2 R_l(r)\]
After solving the equation, we take the asymptotic limit $r \to \infty$, and write $R_l(r)$ as a linear combination of $j_l(kr)\cos \delta_l + n_l(kr) \sin \delta_l $. The relative coefficients of $j_l$ and $n_l$ determines the phase shift $\delta_l$, and hence the cross section.
\end{document}